{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: AlexNet\n",
    "\n",
    "datasets:\n",
    "- train count: 15k\n",
    "- valid count: 6k\n",
    "- test count: 9k\n",
    "\n",
    "Accuracy: 87.6%\n",
    "\n",
    "if we increase the dataset by 10x, the accuracy increases to 98.8%.\n",
    "we can further increase the accuracy to 99.8% using 1M traning images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 datasets/gen_captcha.py -d --npi=4 -n 6\n",
    "# !python3 datasets/base.py ./images/char-4-epoch-6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './images/char-4-epoch-6/train'\n",
    "H, W, C = 100, 120, 3  # height, width, 3(RGB channels)\n",
    "N_LABELS = 256\n",
    "D = 4 # num_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filepath(filepath):\n",
    "    try:\n",
    "        path, filename = os.path.split(filepath)\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "        label, _ = filename.split(\"_\")\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print('error to parse %s. %s' % (filepath, e))\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, age, gender, race, file]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "files = glob.glob(os.path.join(DATA_DIR, \"*.png\"))\n",
    "attributes = list(map(parse_filepath, files))\n",
    "\n",
    "df = pd.DataFrame(attributes, columns=['label', 'age', 'gender', 'race'])\n",
    "df['file'] = files\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count: 0, valid count: 0, test count: 0\n"
     ]
    }
   ],
   "source": [
    "p = np.random.permutation(len(df))\n",
    "train_up_to = int(len(df) * 0.7)\n",
    "train_idx = p[:train_up_to]\n",
    "test_idx = p[train_up_to:]\n",
    "\n",
    "# split train_idx further into training and validation set\n",
    "train_up_to = int(train_up_to * 0.7)\n",
    "train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "print('train count: %s, valid count: %s, test count: %s' % (\n",
    "    len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    images, labels = [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, label = r['file'], r['label']\n",
    "            im = Image.open(file)\n",
    "#             im = im.resize((H, W))\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(np.array(im))\n",
    "            labels.append(np.array([np.array(to_categorical(ord(i), N_LABELS)) for i in label]))\n",
    "            if len(images) >= batch_size:\n",
    "#                 print(np.array(images), np.array(labels))\n",
    "                yield np.array(images), np.array(labels)\n",
    "                images, labels = [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 120, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 118, 32)       896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 49, 59, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 57, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 23, 28, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 26, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 10, 13, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8320)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              8520704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 256)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9626624 (36.72 MB)\n",
      "Trainable params: 9626624 (36.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(H, W, C))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(input_layer)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(D * N_LABELS, activation='softmax')(x)\n",
    "x = layers.Reshape((D, N_LABELS))(x)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 64\n",
    "valid_batch_size = 64\n",
    "train_gen = get_data_generator(df, train_idx, for_training=True, batch_size=batch_size)\n",
    "valid_gen = get_data_generator(df, valid_idx, for_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=5,\n",
    "#                     callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].plot(history.history['accuracy'], label='Train accuracy')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].legend() \n",
    "\n",
    "    axes[1].plot(history.history['loss'], label='Training loss')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].legend()\n",
    "\n",
    "plot_train_history(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loss and accuracy in test dataset\n",
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "x_test, y_test = next(test_gen)\n",
    "\n",
    "y_pred = model.predict_on_batch(x_test)\n",
    "\n",
    "y_true = tf.math.argmax(y_test, axis=-1)\n",
    "y_pred = tf.math.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_y(y):\n",
    "    return ''.join(map(lambda x: chr(int(x)), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "n = 30\n",
    "random_indices = np.random.permutation(n)\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n / n_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 20))\n",
    "for i, img_idx in enumerate(random_indices):\n",
    "    ax = axes.flat[i]\n",
    "    ax.imshow(x_test[img_idx])\n",
    "    ax.set_title('pred: %s' % format_y(y_pred[img_idx]))\n",
    "    ax.set_xlabel('true: %s' % format_y(y_true[img_idx]))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
